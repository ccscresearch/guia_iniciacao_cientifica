## **Fluxo de Trabalho para Captura, Processamento, An√°lise e Classifica√ß√£o de Tr√°fego de Rede**

## 1. Captura de Dados

### Objetivo
Capturar o tr√°fego de rede em tempo real para posterior an√°lise e extra√ß√£o de informa√ß√µes relevantes.

---

### Ferramentas
- [tcpdump](https://www.tcpdump.org/)
- [Wireshark](https://www.wireshark.org/)
- [tshark](https://www.wireshark.org/docs/man-pages/tshark.html) (modo CLI do Wireshark)

---

### Descri√ß√£o
Captura do tr√°fego de rede em formato `.pcap` para an√°lise posterior. Essa etapa envolve a intercepta√ß√£o e armazenamento de pacotes de rede em tempo real. Os dados s√£o frequentemente salvos no formato PCAP, que pode ser analisado com ferramentas de ci√™ncia de dados. As ferramentas listadas permitem realizar capturas tanto de forma interativa (com interface gr√°fica) quanto automatizada (linha de comando).

---

## 2. Exporta√ß√£o dos PCAPs para CSV

### Objetivo
Converter arquivos PCAP para um formato tabular como CSV, para facilitar a an√°lise de dados em ferramentas de ci√™ncia de dados.

---

### Ferramentas
- [tshark](https://www.wireshark.org/docs/man-pages/tshark.html) (op√ß√£o `-T fields` para exportar campos espec√≠ficos)
- Scripts em Python usando [PyShark](https://github.com/KimiNewt/pyshark) e [Scapy](https://scapy.net/) para extra√ß√£o customizada

---

### Descri√ß√£o
Ap√≥s a captura, os arquivos PCAP precisam ser convertidos para um formato tabular, como CSV ou outros formatos mais leves, como `.parquet`. Esse processo facilita a manipula√ß√£o e an√°lise dos dados em ferramentas como Pandas. As ferramentas citadas permitem a extra√ß√£o de atributos importantes dos pacotes, como IPs, portas, protocolos, tamanho de pacotes e flags.

---

## 3. Pr√©-processamento dos Dados

### Objetivo
Limpar e transformar os dados para garantir que estejam prontos para an√°lise estat√≠stica ou treinamento de modelos de IA.

---

### Ferramentas
- [Pandas](https://pandas.pydata.org/) / [Numpy](https://numpy.org/) (Python)
- Scripts customizados em Python
- [Scikit-learn](https://scikit-learn.org/stable/) (para normaliza√ß√£o, codifica√ß√£o de vari√°veis)

---

### Descri√ß√£o
Essa fase envolve o tratamento de dados faltantes, normaliza√ß√£o de valores, codifica√ß√£o de atributos categ√≥ricos e transforma√ß√£o de dados temporais ou textuais. O objetivo √© preparar os dados para an√°lises estat√≠sticas ou para o treinamento de modelos de IA. A manipula√ß√£o de dados √© essencial para garantir que os modelos n√£o sejam impactados por dados inadequados ou inconsistentes.

---

## 4. An√°lise Explorat√≥ria dos Dados

### Objetivo
Explorar e entender a estrutura dos dados, identificar padr√µes e detectar potenciais problemas, como valores ausentes ou outliers.

---

### Ferramentas
- [Pandas](https://pandas.pydata.org/) e [Seaborn](https://seaborn.pydata.org/) (Python)
- [Matplotlib](https://matplotlib.org/)
- [Plotly](https://plotly.com/python/) (para gr√°ficos interativos)

---

### Descri√ß√£o
A an√°lise explorat√≥ria dos dados (EDA) √© uma etapa essencial para entender a distribui√ß√£o e a estrutura dos dados. Durante essa fase, podem ser detectados outliers, verificadas correla√ß√µes entre vari√°veis e visualizados padr√µes de dados. A EDA tamb√©m ajuda a gerar hip√≥teses e a decidir quais caracter√≠sticas dos dados s√£o relevantes para a modelagem.

---

## 5. Correla√ß√£o de Caracter√≠sticas

### Objetivo
Identificar rela√ß√µes entre as vari√°veis do conjunto de dados, o que pode ajudar a selecionar as caracter√≠sticas mais importantes para a modelagem.

---

### Ferramentas
- [Seaborn](https://seaborn.pydata.org/) (heatmap)
- [Pandas](https://pandas.pydata.org/) (.corr())
- [Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html) (Informa√ß√£o M√∫tua)
- [Pingouin](https://pingouin-stats.org/build/html/index.html) (correla√ß√£o de Kendall, Spearman, etc.)

---

### Descri√ß√£o
A an√°lise de correla√ß√£o entre as caracter√≠sticas do conjunto de dados visa identificar redund√¢ncias ou combina√ß√µes √∫teis para a modelagem. Ferramentas como o c√°lculo da correla√ß√£o de Pearson e a an√°lise de informa√ß√µes m√∫tuas podem ser usadas para entender como as vari√°veis est√£o relacionadas. A visualiza√ß√£o atrav√©s de heatmaps facilita a identifica√ß√£o de padr√µes e depend√™ncias entre as vari√°veis.

---

## 6. Sele√ß√£o e Engenharia de Caracter√≠sticas (Opcional)

### Objetivo
Selecionar ou criar caracter√≠sticas mais representativas, melhorando o desempenho do modelo e reduzindo a complexidade computacional.

---

### Ferramentas
- [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) (Principal Component Analysis)
- [RFE](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html) (Recursive Feature Elimination)
- [SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)
- [SVM](https://scikit-learn.org/stable/modules/svm.html#classification) (com coef_ para sele√ß√£o)
- [Featuretools](https://featuretools.alteryx.com/en/stable/) (engenharia autom√°tica de caracter√≠sticas)

---

### Descri√ß√£o
Esta etapa visa selecionar as caracter√≠sticas mais relevantes ou criar novas, mais representativas. T√©cnicas como PCA s√£o usadas para reduzir a dimensionalidade dos dados, enquanto m√©todos como RFE e SVM podem identificar atributos relevantes com base nos pesos dos modelos. Isso pode melhorar tanto o desempenho do modelo quanto reduzir o custo computacional.

---


## 7. Modelagem

### Objetivo
Aplicar algoritmos de *Machine Learning* e *Deep Learning* para resolver tarefas como **classifica√ß√£o**, **regress√£o** ou **clusteriza√ß√£o** com base no tr√°fego de rede analisado.

---

### Divis√£o da Base de Dados
Antes do treinamento de modelos, √© essencial dividir os dados em conjuntos:

- **Treino** (ex: 70%) ‚Äì utilizado para treinar o modelo.
- **Valida√ß√£o** (ex: 15%) ‚Äì usado para ajuste de hiperpar√¢metros.
- **Teste** (ex: 15%) ‚Äì utilizado para avalia√ß√£o final do modelo.

#### T√©cnicas e Ferramentas Utilizadas

- [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html): divis√£o simples dos dados em treino e teste.
- [`KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html): divide os dados em *k* partes para valida√ß√£o cruzada.
- [`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html): como o `KFold`, mas mantendo a propor√ß√£o entre classes.
- [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html): avalia o desempenho de um modelo com valida√ß√£o cruzada de forma simples.

---

### Tarefas Comuns
- **Classifica√ß√£o**: Identifica√ß√£o de ataques, categoriza√ß√£o de tr√°fego.
- **Regress√£o**: Previs√£o de vari√°veis cont√≠nuas como lat√™ncia, throughput.
- **Clusteriza√ß√£o**: Descoberta de padr√µes n√£o rotulados.

---

### Algoritmos Supervisionados
- [K-Nearest Neighbors (KNN)](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)
- [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
- [Support Vector Machine (SVM)](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)
- [Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)
- [XGBoost](https://xgboost.readthedocs.io/en/stable/)

---

### Algoritmos N√£o Supervisionados
- [K-Means](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
- [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)

---

### Redes Neurais / Deep Learning

#### Objetivo
Utilizar arquiteturas mais profundas para capturar padr√µes complexos, especialmente √∫teis em grandes volumes de dados ou sequ√™ncias temporais.

#### Modelos
- [MLP (Multilayer Perceptron)](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)
- [CNN (Convolutional Neural Network)](https://www.tensorflow.org/tutorials/images/cnn) ‚Äì √≥timo para dados espaciais e bidimensionais.
- [RNN / LSTM](https://www.tensorflow.org/tutorials/structured_data/time_series) ‚Äì ideal para s√©ries temporais ou tr√°fego cont√≠nuo.

#### Frameworks Populares
- [TensorFlow](https://www.tensorflow.org/)
- [PyTorch](https://pytorch.org/)

---

> üîÑ **Dica**: Utilize valida√ß√£o cruzada (ex: K-Fold) sempre que poss√≠vel para garantir maior robustez nos resultados.


## 8. Avalia√ß√£o de Modelos

### Objetivo
Medir o desempenho dos modelos em dados n√£o vistos e garantir sua capacidade de generaliza√ß√£o para novos dados.

---

### Etapas

1. **Separa√ß√£o dos Dados**:
   - Caso ainda n√£o tenha sido feita, divida os dados em conjuntos de **treino**, **valida√ß√£o** e **teste**. Isso ajuda a garantir que o modelo n√£o seja sobreajustado (overfitting) aos dados de treino.

2. **Valida√ß√£o Cruzada**:
   - Aplique t√©cnicas como **valida√ß√£o cruzada** (*cross-validation*) para obter estimativas mais confi√°veis sobre o desempenho do modelo. Isso ajuda a reduzir a variabilidade dos resultados.

---

### M√©tricas

- **Acur√°cia**: Propor√ß√£o de previs√µes corretas em rela√ß√£o ao total de amostras.
  - [Acur√°cia - Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)

- **Precis√£o**: Medida da capacidade do modelo de identificar corretamente as inst√¢ncias positivas.
  - [Precis√£o - Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)

- **Revoca√ß√£o (Recall)**: Medida da capacidade do modelo de identificar todas as inst√¢ncias positivas.
  - [Revoca√ß√£o - Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)

- **F1-Score**: M√©dia harm√¥nica entre a precis√£o e a revoca√ß√£o. √ötil quando h√° desbalanceamento entre classes.
  - [F1-Score - Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)

- **Matriz de Confus√£o**: Tabela que mostra o desempenho do modelo em rela√ß√£o a cada classe. Utilizada para calcular outras m√©tricas como precis√£o, revoca√ß√£o, etc.
  - [Matriz de Confus√£o - Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)

- **ROC-AUC**: Medida que avalia a capacidade do modelo de discriminar entre as classes positivas e negativas. Quanto mais pr√≥ximo de 1, melhor.
  - [ROC-AUC - Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)

**Observa√ß√µes**
Dependendo do projeto, podem ser usadas tamb√©m t√©cnicas de balanceamento como [SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html), ou m√©todos de redu√ß√£o de dimensionalidade como [t-SNE](https://lvdmaaten.github.io/tsne/). Todas as etapas devem ser documentadas para permitir a reprodutibilidade dos experimentos.
